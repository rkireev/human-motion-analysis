{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Reshape\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = {}\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in reader:\n",
    "            block = row[-1][1:]\n",
    "            if block.isdigit():\n",
    "                block = int(block)\n",
    "            del row[-1]\n",
    "            del row[0]\n",
    "            if not block in data:\n",
    "                data[block] = {}\n",
    "                data[block]['gyr'] = {}\n",
    "                data[block]['acc'] = {}\n",
    "                data[block]['gyr']['x'] = []\n",
    "                data[block]['gyr']['y'] = []\n",
    "                data[block]['gyr']['z'] = []\n",
    "                data[block]['acc']['x'] = []\n",
    "                data[block]['acc']['y'] = []\n",
    "                data[block]['acc']['z'] = []\n",
    "            frow = np.array(map(float, row))\n",
    "            data[block]['acc']['x'].append(np.array(frow[range(0,len(row),6)]))\n",
    "            data[block]['acc']['y'].append(np.array(frow[range(1,len(row),6)]))\n",
    "            data[block]['acc']['z'].append(np.array(frow[range(2,len(row),6)]))\n",
    "            data[block]['gyr']['x'].append(np.array(frow[range(3,len(row),6)]))\n",
    "            data[block]['gyr']['y'].append(np.array(frow[range(4,len(row),6)]))\n",
    "            data[block]['gyr']['z'].append(np.array(frow[range(5,len(row),6)]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inter(obs, ndots=100):\n",
    "    obs = np.array(obs)\n",
    "    if ndots == -1:\n",
    "        return obs\n",
    "    interpolated = []\n",
    "    x = np.linspace(0, 100, num=obs.shape[0], endpoint=True)\n",
    "    f = interp1d(x, obs, kind='slinear')\n",
    "    xnew = np.linspace(0, 100, num=ndots, endpoint=True)\n",
    "    interpolated.append(f(xnew))\n",
    "    return interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def array_from_dict(data, blocks=range(1, 16), ndots=-1, gyro=True, acc=True):\n",
    "    X = []\n",
    "    y = []\n",
    "    for block in data:\n",
    "        if block in blocks:\n",
    "            for ind in range(len(data[block]['acc']['x'])):\n",
    "                y.append(block)\n",
    "                if gyro and acc:\n",
    "                    X.append(np.dstack((inter(data[block]['acc']['x'][ind], ndots), \n",
    "                                        inter(data[block]['acc']['y'][ind], ndots), \n",
    "                                        inter(data[block]['acc']['z'][ind], ndots), \n",
    "                                        inter(data[block]['gyr']['x'][ind], ndots), \n",
    "                                        inter(data[block]['gyr']['y'][ind], ndots), \n",
    "                                        inter(data[block]['gyr']['z'][ind], ndots))))\n",
    "                if (not gyro) and acc:\n",
    "                    X.append(np.dstack((inter(data[block]['acc']['x'][ind], ndots), \n",
    "                                        inter(data[block]['acc']['y'][ind], ndots), \n",
    "                                        inter(data[block]['acc']['z'][ind], ndots))))\n",
    "                if gyro and (not acc):\n",
    "                    X.append(np.dstack((inter(data[block]['gyr']['x'][ind], ndots), \n",
    "                                        inter(data[block]['gyr']['y'][ind], ndots), \n",
    "                                        inter(data[block]['gyr']['z'][ind], ndots))))\n",
    "    return X, np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lstm(X, y, n_units=None, n_features=None, n_epoch=None):\n",
    "    b = np.zeros((len(y), 16))\n",
    "    b[np.arange(len(y)), y-1] = 1\n",
    "    y = b  # One hot encoded y\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    model = Sequential()  # Creates a model\n",
    "    model.add(LSTM(n_units, input_dim=n_features)) \n",
    "    model.add(Dense(16, activation='sigmoid'))  # Kind of output layer\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    for seq, label in zip(X_train, y_train):\n",
    "        label = label.reshape((1, -1))\n",
    "        model.fit(seq, label, nb_epoch=n_epoch, batch_size=1, verbose=0)\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    scores = []\n",
    "    for seq, label in zip(X_test, y_test):\n",
    "        label = label.reshape((1, -1))\n",
    "        scores.append(model.evaluate(seq, label, verbose=0)[1])\n",
    "        y_pred.append(model.predict_classes(seq, verbose=0)[0])\n",
    "        y_true.append(np.where(label == 1)[1][0])\n",
    "    return np.mean(scores), confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = read_data('data1.csv')  # Your data\n",
    "data2 = read_data('data2.csv')  # My data (I dont have a gyroscope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Can you create a confusion matrix (error matrix) so that we could see if there are certain classes which are typically confused, or the recognition is poor in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, ndots=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.695652173913\n",
      "matrix: \n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 5]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(10):\n",
    "    s, m = lstm(X, y, n_units=120, n_features=6, n_epoch=20)\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. can you select two very different classes (like 1 vs 9 or 11 vs 13) and test how the RNN can learn these two classes? In this case, please use much less hidden units, I think 3-10 would be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, blocks=[1, 9], ndots=-1) # 1 vs. 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.2\n",
      "matrix: \n",
      "[[1 0]\n",
      " [4 0]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(10):\n",
    "    s, m = lstm(X, y, n_units=10, n_features=6, n_epoch=20) # 10 units\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  1.0\n",
      "matrix: \n",
      "[[1 0]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(10):\n",
    "    s, m = lstm(X, y, n_units=40, n_features=6, n_epoch=20) # 40 units\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, blocks=[11, 13], ndots=-1) # 11 vs. 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  1.0\n",
      "matrix: \n",
      "[[2 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(10):\n",
    "    s, m = lstm(X, y, n_units=10, n_features=6, n_epoch=20) # 10 units\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  1.0\n",
      "matrix: \n",
      "[[2 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(10):\n",
    "    s, m = lstm(X, y, n_units=40, n_features=6, n_epoch=20) # 40 units\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. can you  reduce the sampling rate? Maybe there is a very little difference in data points at subsequent time positions like t and t+1. Would you invesitgate the performance when only every 10th or 20th data point is kept in the time seris?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, ndots=10) # each sequence is interpoleted to 10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.521739130435\n",
      "matrix: \n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [3 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(10):\n",
    "    s, m = lstm(X, y, n_units=120, n_features=6, n_epoch=20)\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Can you try RNN on your data (i.e. which does not have gyroscope data). Likewise, can you try using only acc or only gyro data from my data?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, ndots=-1, gyro=False) # your data; acceleration only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.652173913043\n",
      "matrix: \n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 3 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 4]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(10):\n",
    "    s, m = lstm(X, y, n_units=120, n_features=3, n_epoch=20)\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, ndots=-1, acc=False) # your data; gyroscope only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.478260869565\n",
      "matrix: \n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [4 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 5]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(10):\n",
    "    s, m = lstm(X, y, n_units=120, n_features=3, n_epoch=20)\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data2, ndots=-1, gyro=False) # my data; acceleration only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.451612903226\n",
      "matrix: \n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 2]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 2 0 0 0 3 0 2 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(10):\n",
    "    s, m = lstm(X, y, n_units=120, n_features=3, n_epoch=20)\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
