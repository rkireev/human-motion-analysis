{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Steps:\n",
    "* Reinterpolete the datasets in order to all observations to have the same length (20 timestamps)\n",
    "* Roughly estimate parameters of classifiers with both datasets separately and together\n",
    "* Compute first integral and add it to datasets\n",
    "* Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inter(Obs, ndots=100):\n",
    "    interpolated = []\n",
    "    for obs in Obs:\n",
    "        x = np.linspace(0, 100, num=obs.shape[0], endpoint=True)\n",
    "        f = interp1d(x, obs, kind='slinear')\n",
    "        xnew = np.linspace(0, 100, num=ndots, endpoint=True)\n",
    "        interpolated.append(f(xnew))\n",
    "    return interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def integrate(data):\n",
    "    data_int = deepcopy(data)\n",
    "    for block in data_int:\n",
    "        for signal_type in data_int[block]:\n",
    "            for axis in data_int[block][signal_type]:\n",
    "                for obs_ind in range(len(data_int[block][signal_type][axis])):\n",
    "                    data_int[block][signal_type][axis][obs_ind] = np.cumsum(data_int[block][signal_type][axis][obs_ind])\n",
    "    return data_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = {}\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in reader:\n",
    "            block = row[-1][1:]\n",
    "            if block.isdigit():\n",
    "                block = int(block)\n",
    "            del row[-1]\n",
    "            del row[0]\n",
    "            if not block in data:\n",
    "                data[block] = {}\n",
    "                data[block]['gyr'] = {}\n",
    "                data[block]['acc'] = {}\n",
    "                data[block]['gyr']['x'] = []\n",
    "                data[block]['gyr']['y'] = []\n",
    "                data[block]['gyr']['z'] = []\n",
    "                data[block]['acc']['x'] = []\n",
    "                data[block]['acc']['y'] = []\n",
    "                data[block]['acc']['z'] = []\n",
    "            frow = np.array(map(float, row))\n",
    "            data[block]['acc']['x'].append(np.array(frow[range(0,len(row),6)]))\n",
    "            data[block]['acc']['y'].append(np.array(frow[range(1,len(row),6)]))\n",
    "            data[block]['acc']['z'].append(np.array(frow[range(2,len(row),6)]))\n",
    "            data[block]['gyr']['x'].append(np.array(frow[range(3,len(row),6)]))\n",
    "            data[block]['gyr']['y'].append(np.array(frow[range(4,len(row),6)]))\n",
    "            data[block]['gyr']['z'].append(np.array(frow[range(5,len(row),6)]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_from_dict_interpoleted(data, ndots=20, use_gyro=True):\n",
    "    columns = ['block']\n",
    "    if use_gyro:\n",
    "        for signal_type in ['acc', 'gyr']:\n",
    "            for axis in ['x', 'y', 'z']:\n",
    "                for ind in range(ndots):\n",
    "                    columns.append('_'.join((signal_type, axis, str(ind))))\n",
    "    else:\n",
    "        for axis in ['x', 'y', 'z']:\n",
    "            for ind in range(ndots):\n",
    "                columns.append('_'.join(('acc', axis, str(ind))))\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for block in data:\n",
    "        acc_x = inter(data[block]['acc']['x'], ndots)\n",
    "        acc_y = inter(data[block]['acc']['y'], ndots)\n",
    "        acc_z = inter(data[block]['acc']['z'], ndots)\n",
    "        if use_gyro:\n",
    "            gyr_x = inter(data[block]['gyr']['x'], ndots)\n",
    "            gyr_y = inter(data[block]['gyr']['y'], ndots)\n",
    "            gyr_z = inter(data[block]['gyr']['z'], ndots)\n",
    "        #print np.hstack(([[block]]*len(acc_x), acc_x, acc_y, acc_z, gyr_x, gyr_y, gyr_z))\n",
    "            df = df.append(pd.DataFrame(np.hstack(([[block]]*len(acc_x), acc_x, acc_y, acc_z, gyr_x, gyr_y, gyr_z)), columns=columns))\n",
    "        else:\n",
    "            df = df.append(pd.DataFrame(np.hstack(([[block]]*len(acc_x), acc_x, acc_y, acc_z)), columns=columns))\n",
    "    df.reset_index(inplace=True)\n",
    "    del df['index']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = read_data('data1.csv') # Your data\n",
    "data2 = read_data('data2.csv') # My data (I dont have a gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df_from_dict_interpoleted(data1)\n",
    "df2 = df_from_dict_interpoleted(data2)\n",
    "df1_acc = df_from_dict_interpoleted(data1, use_gyro=False)\n",
    "df2_acc = df_from_dict_interpoleted(data2, use_gyro=False)\n",
    "df1_vel = df_from_dict_interpoleted(integrate(data1), use_gyro=False)\n",
    "df2_vel = df_from_dict_interpoleted(integrate(data2), use_gyro=False)\n",
    "df1i = pd.concat([df1, df_from_dict_interpoleted(integrate(data1))], axis=1)\n",
    "df2i = pd.concat([df2, df_from_dict_interpoleted(integrate(data2))], axis=1)\n",
    "df = df1.append(df2).reset_index()\n",
    "dfi = df1i.append(df2i).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target1 = df1['block']\n",
    "del df1['block']\n",
    "X1 = df1\n",
    "target2 = df2['block']\n",
    "del df2['block']\n",
    "X2 = df2\n",
    "target = df['block']\n",
    "del df['block']\n",
    "del df['index']\n",
    "X = df\n",
    "target1i = df1i['block'].ix[:,0]\n",
    "del df1i['block']\n",
    "X1i = df1i.as_matrix()\n",
    "target2i = df2i['block'].ix[:,0]\n",
    "del df2i['block']\n",
    "X2i = df2i.as_matrix()\n",
    "targeti = dfi['block'].ix[:,0]\n",
    "del dfi['block']\n",
    "del dfi['index']\n",
    "Xi = dfi.as_matrix()\n",
    "target1_acc = df1_acc['block']\n",
    "del df1_acc['block']\n",
    "X1_acc = df1_acc\n",
    "target2_acc = df2_acc['block']\n",
    "del df2_acc['block']\n",
    "X2_acc = df2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target1_vel = df1_vel['block']\n",
    "del df1_vel['block']\n",
    "X1_vel = df1_vel\n",
    "target2_vel = df2_vel['block']\n",
    "del df2_vel['block']\n",
    "X2_vel = df2_vel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we have:\n",
    "\n",
    "X1 - first dataset\n",
    "\n",
    "X2 - second dataset\n",
    "\n",
    "X - both datasets \n",
    "\n",
    "X1i - first dataset + its integrated observations\n",
    "\n",
    "X2i - second dataset + its integrated observations\n",
    "\n",
    "Xi - both datasets + its integrated observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we sloppy estimate parameters of XGB and SVM clsfrs. Also we consider a dummy estimator, based on class frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def params_xgb():\n",
    "    max_depth=np.random.choice([5,10,15,20],1)\n",
    "    learning_rate=np.random.choice([0.01, 0.05, 0.1, 0.5, 1],1)\n",
    "    n_estimators=np.random.choice([10, 50, 100, 150, 200, 300],1)\n",
    "    subsample=np.random.choice([0.3, 0.6, 0.7, 0.8, 1],1)\n",
    "    colsample_bytree=np.random.choice([0.4, 0.6, 0.7, 0.8, 1],1)\n",
    "    return XGBClassifier(learning_rate=learning_rate[0], n_estimators=n_estimators[0], max_depth=max_depth[0],\n",
    "                        subsample=subsample[0], colsample_bytree=colsample_bytree[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    xgbc = params_xgb()\n",
    "    scores_xgb = cross_validation.cross_val_score(xgbc, Xi, targeti, cv=4)\n",
    "    if np.mean(scores_xgb)>0.6:\n",
    "        print xgbc\n",
    "        print np.mean(scores_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf']}]\n",
    "grid_search1 = grid_search.GridSearchCV(svc, param_grid=param_grid)\n",
    "grid_search1.fit(Xi, targeti)\n",
    "print(grid_search1.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def svm_xgb_dummy(X, y):\n",
    "    dumb = DummyClassifier()\n",
    "    svc = SVC(kernel='linear')\n",
    "    xgb = XGBClassifier(colsample_bytree=0.4, learning_rate=0.05, max_depth=10, n_estimators=200, subsample=0.6)\n",
    "    scores_svc = cross_validation.cross_val_score(svc, X, y, cv=4)\n",
    "    scores_dumb = cross_validation.cross_val_score(dumb, X, y, cv=4)\n",
    "    scores_xgb = cross_validation.cross_val_score(xgb, X, y, cv=4)\n",
    "    return np.mean(scores_svc), np.mean(scores_xgb), np.mean(scores_dumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['dataset'] = []\n",
    "results['SVM'] = []\n",
    "results['XGB'] = []\n",
    "results['Dummy'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_svm, s_xgb, s_dum = svm_xgb_dummy(X1, target1)\n",
    "results['dataset'].append('data1')\n",
    "results['SVM'].append(s_svm)\n",
    "results['XGB'].append(s_xgb)\n",
    "results['Dummy'].append(s_dum)\n",
    "s_svm, s_xgb, s_dum = svm_xgb_dummy(X2, target2)\n",
    "results['dataset'].append('data2')\n",
    "results['SVM'].append(s_svm)\n",
    "results['XGB'].append(s_xgb)\n",
    "results['Dummy'].append(s_dum)\n",
    "s_svm, s_xgb, s_dum = svm_xgb_dummy(X, target)\n",
    "results['dataset'].append('data1+data2')\n",
    "results['SVM'].append(s_svm)\n",
    "results['XGB'].append(s_xgb)\n",
    "results['Dummy'].append(s_dum)\n",
    "s_svm, s_xgb, s_dum = svm_xgb_dummy(X1i, target1i)\n",
    "results['dataset'].append('data1+integrated')\n",
    "results['SVM'].append(s_svm)\n",
    "results['XGB'].append(s_xgb)\n",
    "results['Dummy'].append(s_dum)\n",
    "s_svm, s_xgb, s_dum = svm_xgb_dummy(X2i, target2i)\n",
    "results['dataset'].append('data2+integrated')\n",
    "results['SVM'].append(s_svm)\n",
    "results['XGB'].append(s_xgb)\n",
    "results['Dummy'].append(s_dum)\n",
    "s_svm, s_xgb, s_dum = svm_xgb_dummy(Xi, targeti)\n",
    "results['dataset'].append('data1+data2+integrated')\n",
    "results['SVM'].append(s_svm)\n",
    "results['XGB'].append(s_xgb)\n",
    "results['Dummy'].append(s_dum)\n",
    "s_svm, s_xgb, s_dum = svm_xgb_dummy(X1_acc, target1_acc)\n",
    "results['dataset'].append('data1 accelerometer only')\n",
    "results['SVM'].append(s_svm)\n",
    "results['XGB'].append(s_xgb)\n",
    "results['Dummy'].append(s_dum)\n",
    "s_svm, s_xgb, s_dum = svm_xgb_dummy(X2_acc, target2_acc)\n",
    "results['dataset'].append('data2 accelerometer only')\n",
    "results['SVM'].append(s_svm)\n",
    "results['XGB'].append(s_xgb)\n",
    "results['Dummy'].append(s_dum)\n",
    "s_svm, s_xgb, s_dum = svm_xgb_dummy(X1_vel, target1_vel)\n",
    "results['dataset'].append('data1 velocity only')\n",
    "results['SVM'].append(s_svm)\n",
    "results['XGB'].append(s_xgb)\n",
    "results['Dummy'].append(s_dum)\n",
    "s_svm, s_xgb, s_dum = svm_xgb_dummy(X2_vel, target2_vel)\n",
    "results['dataset'].append('data2 velocity only')\n",
    "results['SVM'].append(s_svm)\n",
    "results['XGB'].append(s_xgb)\n",
    "results['Dummy'].append(s_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>SVM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058201</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.811234</td>\n",
       "      <td>data1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065368</td>\n",
       "      <td>0.912507</td>\n",
       "      <td>0.794024</td>\n",
       "      <td>data2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082476</td>\n",
       "      <td>0.740380</td>\n",
       "      <td>0.682392</td>\n",
       "      <td>data1+data2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081172</td>\n",
       "      <td>0.938828</td>\n",
       "      <td>0.751285</td>\n",
       "      <td>data1+integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081050</td>\n",
       "      <td>0.909472</td>\n",
       "      <td>0.789767</td>\n",
       "      <td>data2+integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.081209</td>\n",
       "      <td>0.739604</td>\n",
       "      <td>0.701771</td>\n",
       "      <td>data1+data2+integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.098201</td>\n",
       "      <td>0.869435</td>\n",
       "      <td>0.739506</td>\n",
       "      <td>data1 accelerometer only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.057841</td>\n",
       "      <td>0.912507</td>\n",
       "      <td>0.808035</td>\n",
       "      <td>data2 accelerometer only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.051885</td>\n",
       "      <td>0.874079</td>\n",
       "      <td>0.647512</td>\n",
       "      <td>data1 velocity only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.072547</td>\n",
       "      <td>0.909472</td>\n",
       "      <td>0.805909</td>\n",
       "      <td>data2 velocity only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dummy       SVM       XGB                   dataset\n",
       "0  0.058201  0.877500  0.811234                     data1\n",
       "1  0.065368  0.912507  0.794024                     data2\n",
       "2  0.082476  0.740380  0.682392               data1+data2\n",
       "3  0.081172  0.938828  0.751285          data1+integrated\n",
       "4  0.081050  0.909472  0.789767          data2+integrated\n",
       "5  0.081209  0.739604  0.701771    data1+data2+integrated\n",
       "6  0.098201  0.869435  0.739506  data1 accelerometer only\n",
       "7  0.057841  0.912507  0.808035  data2 accelerometer only\n",
       "8  0.051885  0.874079  0.647512       data1 velocity only\n",
       "9  0.072547  0.909472  0.805909       data2 velocity only"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='stratified')"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
