{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Reshape\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = {}\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in reader:\n",
    "            block = row[-1][1:]\n",
    "            if block.isdigit():\n",
    "                block = int(block)\n",
    "            del row[-1]\n",
    "            del row[0]\n",
    "            if not block in data:\n",
    "                data[block] = {}\n",
    "                data[block]['gyr'] = {}\n",
    "                data[block]['acc'] = {}\n",
    "                data[block]['gyr']['x'] = []\n",
    "                data[block]['gyr']['y'] = []\n",
    "                data[block]['gyr']['z'] = []\n",
    "                data[block]['acc']['x'] = []\n",
    "                data[block]['acc']['y'] = []\n",
    "                data[block]['acc']['z'] = []\n",
    "            frow = np.array(map(float, row))\n",
    "            data[block]['acc']['x'].append(np.array(frow[range(0,len(row),6)]))\n",
    "            data[block]['acc']['y'].append(np.array(frow[range(1,len(row),6)]))\n",
    "            data[block]['acc']['z'].append(np.array(frow[range(2,len(row),6)]))\n",
    "            data[block]['gyr']['x'].append(np.array(frow[range(3,len(row),6)]))\n",
    "            data[block]['gyr']['y'].append(np.array(frow[range(4,len(row),6)]))\n",
    "            data[block]['gyr']['z'].append(np.array(frow[range(5,len(row),6)]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inter(obs, ndots=100):\n",
    "    obs = np.array(obs)\n",
    "    if ndots == -1:\n",
    "        return obs\n",
    "    interpolated = []\n",
    "    x = np.linspace(0, 100, num=obs.shape[0], endpoint=True)\n",
    "    f = interp1d(x, obs, kind='slinear')\n",
    "    xnew = np.linspace(0, 100, num=ndots, endpoint=True)\n",
    "    interpolated.append(f(xnew))\n",
    "    return interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def array_from_dict(data, blocks=range(1, 16), ndots=-1, gyro=True, acc=True):\n",
    "    X = []\n",
    "    y = []\n",
    "    for block in data:\n",
    "        if block in blocks:\n",
    "            for ind in range(len(data[block]['acc']['x'])):\n",
    "                y.append(block)\n",
    "                if gyro and acc:\n",
    "                    X.append(np.dstack((inter(data[block]['acc']['x'][ind], ndots), \n",
    "                                        inter(data[block]['acc']['y'][ind], ndots), \n",
    "                                        inter(data[block]['acc']['z'][ind], ndots), \n",
    "                                        inter(data[block]['gyr']['x'][ind], ndots), \n",
    "                                        inter(data[block]['gyr']['y'][ind], ndots), \n",
    "                                        inter(data[block]['gyr']['z'][ind], ndots))))\n",
    "                if (not gyro) and acc:\n",
    "                    X.append(np.dstack((inter(data[block]['acc']['x'][ind], ndots), \n",
    "                                        inter(data[block]['acc']['y'][ind], ndots), \n",
    "                                        inter(data[block]['acc']['z'][ind], ndots))))\n",
    "                if gyro and (not acc):\n",
    "                    X.append(np.dstack((inter(data[block]['gyr']['x'][ind], ndots), \n",
    "                                        inter(data[block]['gyr']['y'][ind], ndots), \n",
    "                                        inter(data[block]['gyr']['z'][ind], ndots))))\n",
    "    return X, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(data, var, n):\n",
    "    data_noise = deepcopy(data)\n",
    "    for block in data:\n",
    "        for ind in np.random.choice(range(len(data[block]['acc']['x'])), n):\n",
    "            obs = np.vstack((data[block]['acc']['x'][ind], data[block]['acc']['y'][ind], \n",
    "                             data[block]['acc']['z'][ind], data[block]['gyr']['x'][ind], \n",
    "                             data[block]['gyr']['y'][ind], data[block]['gyr']['z'][ind]))\n",
    "            obs = obs + np.transpose(np.random.multivariate_normal(np.zeros(6), \n",
    "                                                                   var*np.identity(6), \n",
    "                                                                   len(data[block]['gyr']['z'][ind])))\n",
    "            data_noise[block]['acc']['x'].append(obs[0])\n",
    "            data_noise[block]['acc']['y'].append(obs[1])\n",
    "            data_noise[block]['acc']['z'].append(obs[2])\n",
    "            data_noise[block]['gyr']['x'].append(obs[3])\n",
    "            data_noise[block]['gyr']['y'].append(obs[4])\n",
    "            data_noise[block]['gyr']['z'].append(obs[5])\n",
    "            \n",
    "    return data_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lstm(X, y, n_units=None, n_features=None, n_epoch=None):\n",
    "    b = np.zeros((len(y), 16))\n",
    "    b[np.arange(len(y)), y-1] = 1\n",
    "    y = b  # One hot encoded y\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    model = Sequential()  # Creates a model\n",
    "    model.add(LSTM(n_units, input_dim=n_features)) \n",
    "    model.add(Dense(16, activation='sigmoid'))  # Kind of output layer\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    for seq, label in zip(X_train, y_train):\n",
    "        label = label.reshape((1, -1))\n",
    "        model.fit(seq, label, nb_epoch=n_epoch, batch_size=1, verbose=0)\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    scores = []\n",
    "    for seq, label in zip(X_test, y_test):\n",
    "        label = label.reshape((1, -1))\n",
    "        scores.append(model.evaluate(seq, label, verbose=0)[1])\n",
    "        y_pred.append(model.predict_classes(seq, verbose=0)[0])\n",
    "        y_true.append(np.where(label == 1)[1][0])\n",
    "    return np.mean(scores), confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = read_data('data1.csv')  # Your data\n",
    "data2 = read_data('data2.csv')  # My data (I dont have a gyroscope)\n",
    "data1 = add_noise(data1, 0.5, 100)  # Your data\n",
    "data2 = add_noise(data2, 0.5, 100)  # My data (I dont have a gyroscope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Can you create a confusion matrix (error matrix) so that we could see if there are certain classes which are typically confused, or the recognition is poor in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, ndots=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  1.0\n",
      "matrix: \n",
      "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 17  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 25  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 16  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 17  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 25  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 23  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 21  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 19  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 19  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 22  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 31  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 22  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(3):\n",
    "    s, m = lstm(X, y, n_units=120, n_features=6, n_epoch=20)\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. can you select two very different classes (like 1 vs 9 or 11 vs 13) and test how the RNN can learn these two classes? In this case, please use much less hidden units, I think 3-10 would be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, blocks=[1, 9], ndots=-1) # 1 vs. 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  1.0\n",
      "matrix: \n",
      "[[26  0]\n",
      " [ 0 19]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(3):\n",
    "    s, m = lstm(X, y, n_units=10, n_features=6, n_epoch=20) # 10 units\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '5744' (I am process '5602')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  1.0\n",
      "matrix: \n",
      "[[26  0]\n",
      " [ 0 19]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(3):\n",
    "    s, m = lstm(X, y, n_units=40, n_features=6, n_epoch=20) # 40 units\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, blocks=[11, 13], ndots=-1) # 11 vs. 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.886363636364\n",
      "matrix: \n",
      "[[24  2]\n",
      " [ 3 15]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(3):\n",
    "    s, m = lstm(X, y, n_units=10, n_features=6, n_epoch=20) # 10 units\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  1.0\n",
      "matrix: \n",
      "[[26  0]\n",
      " [ 0 18]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(3):\n",
    "    s, m = lstm(X, y, n_units=40, n_features=6, n_epoch=20) # 40 units\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. can you  reduce the sampling rate? Maybe there is a very little difference in data points at subsequent time positions like t and t+1. Would you invesitgate the performance when only every 10th or 20th data point is kept in the time seris?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, ndots=10) # each sequence is interpoleted to 10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.996904024768\n",
      "matrix: \n",
      "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 17  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 25  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 16  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 17  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 25  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 23  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 21  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 19  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 19  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 21  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 31  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 22  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(3):\n",
    "    s, m = lstm(X, y, n_units=120, n_features=6, n_epoch=20)\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Can you try RNN on your data (i.e. which does not have gyroscope data). Likewise, can you try using only acc or only gyro data from my data?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, ndots=-1, gyro=False) # your data; acceleration only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.996904024768\n",
      "matrix: \n",
      "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 17  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 25  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 16  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 17  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 25  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 23  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 21  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 19  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 19  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 22  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 31  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0 21  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(3):\n",
    "    s, m = lstm(X, y, n_units=120, n_features=3, n_epoch=20)\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data1, ndots=-1, acc=False) # your data; gyroscope only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.0712074303406\n",
      "matrix: \n",
      "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [17  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [25  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [16  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [17  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [25  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [23  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [21  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [19  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [19  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [22  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [31  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [25  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [22  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [18  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(3):\n",
    "    s, m = lstm(X, y, n_units=120, n_features=3, n_epoch=20)\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = array_from_dict(data2, ndots=-1, gyro=False) # my data; acceleration only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.885196374622\n",
      "matrix: \n",
      "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 18  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 26  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 14  0  0  0  0  0  0  4  1  0  0  0]\n",
      " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 22  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 24  0  1  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 18  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0 19  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  2  0  0  0 18  0  3  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0 28  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  8  0  0  0 19  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0 16  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  4  1  0 15]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "matrices = []\n",
    "for i in range(3):\n",
    "    s, m = lstm(X, y, n_units=120, n_features=3, n_epoch=20)\n",
    "    scores.append(s)\n",
    "    matrices.append(m)\n",
    "print 'score: ', np.max(scores)\n",
    "print 'matrix: '\n",
    "print matrices[np.where(np.array(scores) == np.max(scores))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
